{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7df6472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### '''Import packages'''\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from html.parser import HTMLParser\n",
    "from datetime import datetime\n",
    "from datetime import date, timedelta\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdbfce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter in date range\n",
    "start_date = date(2024, 10, 22)\n",
    "end_date = date(2025, 2, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "860282c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dates_between(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Generates a list of dates between two dates (inclusive).\n",
    "\n",
    "    Args:\n",
    "        start_date (date): The starting date.\n",
    "        end_date (date): The ending date.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dates between start_date and end_date.\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        dates.append(current_date)\n",
    "        current_date += timedelta(days=1)\n",
    "    return dates\n",
    "\n",
    "def daily_stats_url_list():\n",
    "    \"\"\"\n",
    "    Generates a list of url to access Daily Stats from Basketball Reference Site\n",
    "    \n",
    "    Args:\n",
    "        season_start_year (year): The starting year.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of url to access Daily Stats from Basketball Reference Site.    \n",
    "    \"\"\"\n",
    "    url_list = []\n",
    "\n",
    "    for dt in date_list:\n",
    "        urldata = \"https://www.basketball-reference.com/friv/dailyleaders.fcgi?month=\"\\\n",
    "        +str(dt.month)+\"&day=\"+str(dt.day)+\"&year=\"+str(dt.year)+\"&type=all\"\n",
    "        url_list.append(urldata)\n",
    "        \n",
    "    valid_url = []\n",
    "    \n",
    "    for item in url_list:\n",
    "            r = requests.get(item, headers={'User-Agent': random.choice(useragents)})\n",
    "            soup_new = BeautifulSoup(r.text,'html.parser')\n",
    "            league_table = soup_new.find('table', class_='sortable stats_table')\n",
    "            if league_table is not None:\n",
    "                #print(item)\n",
    "                valid_url.append(item)\n",
    "            else:\n",
    "                print('Error')\n",
    "            time.sleep(random.randint(20,30))\n",
    "    return(valid_url)\n",
    "\n",
    "def url_date_substring(url_string):\n",
    "    \"\"\"\n",
    "    Generates a date array by parsing through text to grab year, month, and day.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dates between start_date and end_date.\n",
    "    \"\"\"    \n",
    "    date_array = []\n",
    "    pattern = r\"\\=(.*?)\\&\"\n",
    "    matches = re.findall(pattern, url_string)\n",
    "    for match in matches:\n",
    "        date_array.append(match)\n",
    "    return(date_array)\n",
    "\n",
    "def url_date_substring_loop():\n",
    "    \"\"\"\n",
    "    Loop through URL's to grab year, month, and day.\n",
    "\n",
    "    Returns:\n",
    "        list: Full list of dates between start_date and end_date.\n",
    "    \"\"\"      \n",
    "    url_date_substring_loop = []\n",
    "    x=0\n",
    "    for item in daily_stats_url_val:\n",
    "        cnt_val = 1\n",
    "        val = url_date_substring(url_string = daily_stats_url_val[x] )\n",
    "        url_date_substring_loop.append(val)\n",
    "        x= x + cnt_val\n",
    "    return(url_date_substring_loop)\n",
    "\n",
    "def bs4(urldata):\n",
    "    \"\"\"\n",
    "    Open URL and parse through text to find table with specific class name.\n",
    "\n",
    "    Returns:\n",
    "        list: Returns table.\n",
    "    \"\"\"   \n",
    "    #urldata = \"https://www.basketball-reference.com/friv/dailyleaders.fcgi?month=10&day=1&year=2024&type=all\"\n",
    "    #urldata = \"https://www.basketball-reference.com/friv/dailyleaders.fcgi?month=10&day=22&year=2024&type=all\"\n",
    "    r = requests.get(urldata, headers={'User-Agent': random.choice(useragents)})\n",
    "    soup_new = BeautifulSoup(r.text,'html.parser')\n",
    "    league_table = soup_new.find('table', class_='sortable stats_table')\n",
    "    return(league_table)\n",
    "\n",
    "def Source_check(urldata):\n",
    "    \"\"\"\n",
    "    Confirm website is active.\n",
    "\n",
    "    \"\"\"       \n",
    "    a = urllib.request.urlopen(urldata)\n",
    "    if a.getcode() == 200:\n",
    "        print(\"Result code: \" + str(a.getcode()))\n",
    "    else:\n",
    "        print(\"Error, cannot parse results\")\n",
    "        \n",
    "def Header_row(league_table):\n",
    "    \"\"\"\n",
    "    Finder header row of table and create list of column names for final dataframe.\n",
    "\n",
    "    \"\"\"       \n",
    "\thead = league_table.find('thead')\n",
    "\tcol = []\n",
    "\tcolumn_name = re.findall('label=\"(.+?)\"', str(head))\n",
    "\tst = column_name\n",
    "\tfor i in st:\n",
    "\t\tlist_i = [i]\n",
    "\t\tcol.extend(list_i)\n",
    "\tcolumn_name.remove('Rk')\n",
    "\treturn(column_name)\n",
    "\n",
    "def nba_player_data(league_table):\n",
    "    \"\"\"\n",
    "    Parase through text to find player data\n",
    "\n",
    "    \"\"\"     \n",
    "\ti = 0\n",
    "\tnba_player_data_list = []\n",
    "\tfor team in league_table.find_all('tbody'):\n",
    "\t\trows = team.find_all('tr')\n",
    "\t\tfor row in rows:\n",
    "\t\t\tif i < 700:\n",
    "\t\t\t\ti += 1\n",
    "\t\t\t\tnba_players = row.find_all('td')\n",
    "\t\t\t\tfor player in nba_players:\n",
    "\t\t\t\t\tnba_player_data_list.append(player)\n",
    "\treturn(nba_player_data_list)\n",
    "\n",
    "def actual_data(league_table):\n",
    "    \"\"\"\n",
    "    Parase through text to get statistics and apend them to.  Looks for values in between certain characters.\n",
    "\n",
    "    \"\"\"         \n",
    "\tlist_ = nba_player_data(league_table)\n",
    "\tmax_list_count = len(list_)\n",
    "\tcol = []\n",
    "\tfor num in range (0,max_list_count,1):\n",
    "\t\tif num ==0 or num%(len(Header_row(league_table)))==0:\n",
    "\t\t\tname = re.search('csk=\"(.+?)\"',str(list_[num]))\n",
    "\t\t\tif name:\n",
    "\t\t\t\tcol.append(name.group(1))\n",
    "\t\telse:\n",
    "\t\t\tactual_value = re.search('\">(.+?)<',str(list_[num]))\n",
    "\t\t\tif actual_value is not None:\n",
    "\t\t\t\tcol.append(actual_value.group(1))\n",
    "\t\t\telse:\n",
    "\t\t\t\tcol.append('0.0')\n",
    "\treturn(col)\n",
    "\n",
    "def list_partition(league_table):\n",
    "    \"\"\"\n",
    "    Create dataframe with full list of stats .\n",
    "\n",
    "    \"\"\"      \n",
    "\tmain = actual_data(league_table)\n",
    "\tstart= 0\n",
    "\tint = len(Header_row(league_table))\n",
    "\tvariable_assign = ['x']\n",
    "\ttot = len(main)\n",
    "\tdf = pd.DataFrame(columns = Header_row(league_table))\n",
    "\twhile start < tot:\n",
    "\t\tfor part in variable_assign:\n",
    "\t\t\tpart = main[start:(start + int)]\n",
    "\t\t\tdf_length = len(df)\n",
    "\t\t\tdf.loc[df_length] = part\n",
    "\t\t\tbreak\n",
    "\t\tstart += int\n",
    "\treturn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ff0410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare variables\n",
    "useragents = ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:134.0) Gecko/20100101 Firefox/134.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36 Edg/132.0.0.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:135.0) Gecko/20100101 Firefox/135.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 YaBrowser/24.12.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 Edg/133.0.0.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 OPR/116.0.0.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:128.0) Gecko/20100101 Firefox/128.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:133.0) Gecko/20100101 Firefox/133.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 OPR/115.0.0.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 GLS/100.10.9939.100',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 OPR/114.0.0.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:136.0) Gecko/20100101 Firefox/136.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; rv:128.0) Gecko/20100101 Firefox/128.0',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',\n",
    "'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0']\n",
    "\n",
    "now = datetime.now()\n",
    "file_date = (now.strftime(\"%d_%b_%Y\"))\n",
    "file_date.replace(r\"/\",\".\")\n",
    "file_name = \"NBAPlayerDailyStats.csv\"\n",
    "dfs = []\n",
    "x=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9ca654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "#Execute functions\n",
    "date_list = list_dates_between(start_date, end_date)\n",
    "\n",
    "daily_stats_url_val = daily_stats_url_list()\n",
    "\n",
    "url_date_substring_loop_val = url_date_substring_loop()\n",
    "\n",
    "#Loop through all url's in given date range\n",
    "for item in daily_stats_url_val:\n",
    "    url = bs4(item)\n",
    "    Header_row(url)\n",
    "    nba_player_data(url)\n",
    "    actual_data(url)\n",
    "    df = list_partition(url)\n",
    "    cnt_val = 1\n",
    "    dateval = url_date_substring_loop_val[x]\n",
    "    x =x + cnt_val\n",
    "    df['Player']= df['Player'].str.replace('-1', '') #Removes special characters from player name. \n",
    "    df['Tm']=df['Tm'].str.slice(-3) #Removes URL link from team name.\n",
    "    df['Opp']=df['Opp'].str.slice(-3) #Removes URL link from team name.\n",
    "    df = df.replace('<strong>', '', regex=True) #Replaces characters from all strings in all cells.\n",
    "    game_date = date(int(dateval[2]),int(dateval[0]),int(dateval[1]))\n",
    "    df['Game Date'] = game_date\n",
    "    dfs.append(df)\n",
    "\n",
    "#Concatenate all dataframes \n",
    "final_df = pd.concat(dfs,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df6d6252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create CSV File\n",
    "final_df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
